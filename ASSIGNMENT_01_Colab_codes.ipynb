{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In this Assignment the MNIST dataset was downloaded from Github through the following link:  https://git-disl.github.io/GTDLBench/datasets/mnist_datasets/"
      ],
      "metadata": {
        "id": "kzjJ8CRPucac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code for importing data\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def load_data():\n",
        "    def _load_data(filename, num_samples, offset):\n",
        "        with open(filename, 'rb') as f:\n",
        "            f.read(offset)\n",
        "            data = np.frombuffer(f.read(num_samples * 28 * 28), dtype=np.uint8)\n",
        "        return data.reshape(num_samples, 28*28)\n",
        "\n",
        "    def _load_labels(filename, num_samples, offset):\n",
        "        with open(filename, 'rb') as f:\n",
        "            f.read(offset)\n",
        "            labels = np.frombuffer(f.read(num_samples), dtype=np.uint8)\n",
        "        return labels.reshape(num_samples, 1)\n",
        "\n",
        "    train_images = _load_data('train-images.idx3-ubyte', 60000, 16)\n",
        "    train_labels = _load_labels('train-labels.idx1-ubyte', 60000, 8)\n",
        "    test_images = _load_data('t10k-images.idx3-ubyte', 10000, 16)\n",
        "    test_labels = _load_labels('t10k-labels.idx1-ubyte', 10000, 8)\n",
        "\n",
        "    return train_images, train_labels, test_images, test_labels\n",
        "\n",
        "# Load the data\n",
        "train_images, train_labels, test_images, test_labels = load_data()"
      ],
      "metadata": {
        "id": "i-dSwhFiuXaK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# codes for displaying a few images and their corresponding labels\n",
        "import matplotlib.pyplot as plt\n",
        "num_images_to_display = 5\n",
        "fig, axes = plt.subplots(1, num_images_to_display, figsize=(12, 3))\n",
        "for i in range(num_images_to_display):\n",
        "    axes[i].imshow(train_images[i].reshape(28, 28), cmap='gray')\n",
        "    axes[i].set_title(f\"Label: {train_labels[i][0]}\")\n",
        "    axes[i].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "Mk7yELBWvG0i",
        "outputId": "c694fea7-77c6-490a-ecf7-768e5cc0134d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x300 with 5 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAEICAYAAACOB0fcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAhCUlEQVR4nO3dfZSWZZ3A8euBQV4EhuVFMEuURM0CUQRclgQDsRALgyRL0XLNE6Icj7CsLimbSihgiopx5IiQnEMeEDHbFtvlpUwcIdI9aBCBRCCHQORVhGXn3j86cFKYa2CemeuZZ/h8zuEP5/vc9/Nj9MLxxy2Ty7IsCwAAAACQUL1CDwAAAADAycdSCgAAAIDkLKUAAAAASM5SCgAAAIDkLKUAAAAASM5SCgAAAIDkLKUAAAAASM5SCgAAAIDkLKUAAAAASM5Sqshs2LAh5HK5MGnSpGq755IlS0IulwtLliyptnsCf+PMQnFxZqG4OLNQXJxZPslSKoFnn3025HK5sGLFikKPUiPGjRsXcrncUT8aNWpU6NGgSur6mQ0hhM2bN4drr702tGjRIjRv3jx87WtfC+vXry/0WFAlJ8OZ/XtXXHFFyOVyYcSIEYUeBaqkrp/ZNWvWhDvvvDP07NkzNGrUKORyubBhw4ZCjwVVVtfPbAghzJkzJ1x88cWhUaNGoU2bNuHmm28O27dvL/RYJ4WSQg9A3fHUU0+Fpk2bHvnr+vXrF3AaoCJ79+4Nl19+edi1a1e45557QoMGDcKPf/zj0Lt37/Dmm2+GVq1aFXpEoAIvvPBCWLZsWaHHACKWLVsWpkyZEi644ILwuc99Lrz55puFHgmIeOqpp8Lw4cND3759wyOPPBI2bdoUHnvssbBixYpQVlbmYYsaZilFtRkyZEho3bp1occAKjF16tSwdu3a8MYbb4Ru3bqFEEL4yle+Er7whS+EyZMnh/Hjxxd4QuBYPvroo3DXXXeFMWPGhHvvvbfQ4wAV+OpXvxp27twZmjVrFiZNmmQpBbXYwYMHwz333BMuu+yy8Ktf/SrkcrkQQgg9e/YMV199dXj66afD7bffXuAp6zb/+14tcfDgwXDvvfeGrl27htLS0nDqqaeGL37xi2Hx4sUVXvPjH/84tG/fPjRu3Dj07t07rFq16qjXrF69OgwZMiS0bNkyNGrUKFxyySXhpZdeqnSeDz/8MKxevfqEHlnMsizs3r07ZFl23NdAsSrmMzt37tzQrVu3IwupEEI4//zzQ9++fcPzzz9f6fVQjIr5zB728MMPh/Ly8jBq1KjjvgaKVTGf2ZYtW4ZmzZpV+jqoS4r1zK5atSrs3LkzDB069MhCKoQQBg4cGJo2bRrmzJlT6XuRH0upWmL37t1h+vTpoU+fPuGhhx4K48aNC9u2bQtXXnnlMX93ZdasWWHKlCnhtttuC3fffXdYtWpV+NKXvhS2bt165DVvv/12uPTSS8Mf/vCH8K//+q9h8uTJ4dRTTw2DBg0K8+fPj87zxhtvhM997nPhiSeeOO6fQ4cOHUJpaWlo1qxZuP766z82C9Q1xXpmy8vLw//8z/+ESy655KjWvXv3sG7durBnz57j+yRAESnWM3vYxo0bw4QJE8JDDz0UGjdufEI/dyhGxX5m4WRTrGf2wIEDIYRwzH+3Nm7cOPz+978P5eXlx/EZoMoyatyMGTOyEEK2fPnyCl9z6NCh7MCBAx/72AcffJC1bds2++53v3vkY++++24WQsgaN26cbdq06cjHy8rKshBCdueddx75WN++fbNOnTplH3300ZGPlZeXZz179sw6dux45GOLFy/OQgjZ4sWLj/rYfffdV+nP79FHH81GjBiRzZ49O5s7d242cuTIrKSkJOvYsWO2a9euSq+H2qYun9lt27ZlIYTshz/84VHtySefzEII2erVq6P3gNqmLp/Zw4YMGZL17NnzyF+HELLbbrvtuK6F2uZkOLOHTZw4MQshZO++++4JXQe1SV0+s9u2bctyuVx28803f+zjq1evzkIIWQgh2759e/Qe5MeTUrVE/fr1wymnnBJC+NuTDDt27AiHDh0Kl1xySVi5cuVRrx80aFA444wzjvx19+7dQ48ePcJ//Md/hBBC2LFjR1i0aFG49tprw549e8L27dvD9u3bw/vvvx+uvPLKsHbt2rB58+YK5+nTp0/IsiyMGzeu0tlHjhwZHn/88fCtb30rDB48ODz66KNh5syZYe3atWHq1Kkn+JmA4lCsZ3b//v0hhBAaNmx4VDv8hzgefg3UJcV6ZkMIYfHixWHevHnh0UcfPbGfNBSxYj6zcDIq1jPbunXrcO2114aZM2eGyZMnh/Xr14ff/OY3YejQoaFBgwYhBF8b1zRLqVpk5syZoXPnzqFRo0ahVatWoU2bNuEXv/hF2LVr11Gv7dix41EfO/fcc498u9k//elPIcuy8IMf/CC0adPmYz/uu+++EEIIf/3rX2vs5/Ktb30rtGvXLvzXf/1Xjb0HFFoxntnDjyYfflT573300Ucfew3UNcV4Zg8dOhTuuOOOcMMNN3zsz4GDk0Exnlk4mRXrmZ02bVoYMGBAGDVqVPjsZz8bLrvsstCpU6dw9dVXhxDCx77DPNXPd9+rJZ577rlw0003hUGDBoXRo0eH0047LdSvXz/86Ec/CuvWrTvh+x3+/15HjRoVrrzyymO+5pxzzslr5sp85jOfCTt27KjR94BCKdYz27Jly9CwYcOwZcuWo9rhj33qU5/K+32gtinWMztr1qywZs2aMG3atCNfqB+2Z8+esGHDhnDaaaeFJk2a5P1eUJsU65mFk1Uxn9nS0tKwYMGCsHHjxrBhw4bQvn370L59+9CzZ8/Qpk2b0KJFi2p5H47NUqqWmDt3bujQoUN44YUXPvan/h/eAn/S2rVrj/rYH//4x3DWWWeFEP72h46HEEKDBg1Cv379qn/gSmRZFjZs2BAuuuii5O8NKRTrma1Xr17o1KlTWLFixVGtrKwsdOjQwXcMok4q1jO7cePG8L//+7/hn/7pn45qs2bNCrNmzQrz588PgwYNqrEZoBCK9czCyaounNkzzzwznHnmmSGEEHbu3Bl+97vfhcGDByd575OZ/32vlqhfv34I4W/LnMPKysrCsmXLjvn6F1988WP/D+0bb7wRysrKwle+8pUQQginnXZa6NOnT5g2bdoxn4jYtm1bdJ4T+ba3x7rXU089FbZt2xa+/OUvV3o9FKNiPrNDhgwJy5cv/9hias2aNWHRokXhG9/4RqXXQzEq1jP7zW9+M8yfP/+oHyGEMGDAgDB//vzQo0eP6D2gGBXrmYWTVV07s3fffXc4dOhQuPPOO6t0PcfPk1IJPfPMM+E///M/j/r4yJEjw8CBA8MLL7wQrrnmmnDVVVeFd999N/zkJz8JF1xwQdi7d+9R15xzzjmhV69e4fvf/344cOBAePTRR0OrVq3Cv/zLvxx5zZNPPhl69eoVOnXqFG655ZbQoUOHsHXr1rBs2bKwadOm8NZbb1U46xtvvBEuv/zycN9991X6h8O1b98+DB06NHTq1Ck0atQovPrqq2HOnDmhS5cu4dZbbz3+TxDUMnX1zA4fPjw8/fTT4aqrrgqjRo0KDRo0CI888kho27ZtuOuuu47/EwS1TF08s+eff344//zzj9nOPvtsT0hR1OrimQ0hhF27doXHH388hBDCb3/72xBCCE888URo0aJFaNGiRRgxYsTxfHqg1qmrZ3bChAlh1apVoUePHqGkpCS8+OKL4ZVXXgkPPPCAP88xhfTf8O/kc/hbaFb04y9/+UtWXl6ejR8/Pmvfvn3WsGHD7KKLLspefvnl7MYbb8zat29/5F6Hv4XmxIkTs8mTJ2ef+cxnsoYNG2Zf/OIXs7feeuuo9163bl02bNiwrF27dlmDBg2yM844Ixs4cGA2d+7cI6/J99ve/vM//3N2wQUXZM2aNcsaNGiQnXPOOdmYMWOy3bt35/Npg4Kp62c2y7LsL3/5SzZkyJCsefPmWdOmTbOBAwdma9eureqnDArqZDiznxRCyG677bYqXQuFVtfP7OGZjvXj72eHYlHXz+zLL7+cde/ePWvWrFnWpEmT7NJLL82ef/75fD5lnIBclv3d83UAAAAAkIA/UwoAAACA5CylAAAAAEjOUgoAAACA5CylAAAAAEjOUgoAAACA5CylAAAAAEjOUgoAAACA5EqO94W5XK4m5wCOIcuyKl/rzEJ6ziwUF2cWioszC8XleM6sJ6UAAAAASM5SCgAAAIDkLKUAAAAASM5SCgAAAIDkLKUAAAAASM5SCgAAAIDkLKUAAAAASM5SCgAAAIDkLKUAAAAASM5SCgAAAIDkLKUAAAAASM5SCgAAAIDkLKUAAAAASM5SCgAAAIDkLKUAAAAASM5SCgAAAIDkLKUAAAAASM5SCgAAAIDkLKUAAAAASM5SCgAAAIDkLKUAAAAASM5SCgAAAIDkLKUAAAAASM5SCgAAAIDkLKUAAAAASM5SCgAAAIDkLKUAAAAASM5SCgAAAIDkLKUAAAAASM5SCgAAAIDkLKUAAAAASK6k0AMAcGK6du0a7SNGjIj2YcOGRfusWbOi/fHHH4/2lStXRjsAAEAInpQCAAAAoAAspQAAAABIzlIKAAAAgOQspQAAAABIzlIKAAAAgOQspQAAAABIzlIKAAAAgORyWZZlx/XCXK6mZ6EC9evXj/bS0tIaff8RI0ZEe5MmTaL9vPPOi/bbbrst2idNmlRhu+6666LXfvTRR9E+YcKEaP/3f//3aK9px3k8j8mZLV5dunSJ9kWLFkV78+bNq3Gao+3atSvaW7VqVaPvX5s5sxSjvn37Vthmz54dvbZ3797RvmbNmirNlIozSyGMHTs22iv7+rNevYqfK+jTp0/02qVLl0Z7befMQnE5njPrSSkAAAAAkrOUAgAAACA5SykAAAAAkrOUAgAAACA5SykAAAAAkrOUAgAAACA5SykAAAAAkisp9ADF4Mwzz4z2U045Jdp79uwZ7b169Yr2Fi1aRPvgwYOjvdA2bdoU7VOmTIn2a665psK2Z8+e6LVvvfVWtC9dujTaoSZ079492ufNmxftpaWl0Z5lWbRXdm4OHjwY7a1atYr2Sy+9tMK2cuXKvN6bmnPZZZdFe2V/3+fPn1+d45BQt27dKmzLly9POAnUDTfddFO0jxkzJtrLy8ur/N6VfQ0AUNt4UgoAAACA5CylAAAAAEjOUgoAAACA5CylAAAAAEjOUgoAAACA5CylAAAAAEiupNAD1AZdunSJ9kWLFkV7Zd+eva6r7NvWjh07Ntr37t0b7bNnz66wbdmyJXrtBx98EO1r1qyJdjiWJk2aRPvFF18c7c8991y0n3766Sc804lYu3ZttD/88MPRPmfOnGj/7W9/W2Gr7NeDH/3oR9FOzenTp0+0d+zYMdrnz59fjdNQnerVi/8e5Nlnn11ha9++ffTaXC5XpZmgLqvs3DRq1CjRJFA79OjRI9qvv/76aO/du3e0f/7znz/hmf7eqFGjov29996L9l69ekV77Gv/srKy6LUnA09KAQAAAJCcpRQAAAAAyVlKAQAAAJCcpRQAAAAAyVlKAQAAAJCcpRQAAAAAyVlKAQAAAJBcSaEHqA02btwY7e+//360l5aWVuc41a6srCzad+7cGe2XX355tB88eDDaf/rTn0Y7FJtp06ZF+3XXXZdokqq5+OKLo71p06bRvnTp0mjv06dPha1z587RaymcYcOGRfuyZcsSTUJ1O/3006P9lltuqbA999xz0WtXr15dpZmgmPXr1y/ab7/99rzuX9m5GjhwYIVt69ateb03VMXQoUOj/bHHHov21q1bR3sul4v2JUuWRHubNm2ifeLEidFemcrmi73/N7/5zbzeuy7wpBQAAAAAyVlKAQAAAJCcpRQAAAAAyVlKAQAAAJCcpRQAAAAAyVlKAQAAAJCcpRQAAAAAyZUUeoDaYMeOHdE+evToaB84cGC0//73v4/2KVOmRHtl3nzzzWi/4ooron3fvn3R/vnPfz7aR44cGe1QbLp27RrtV111VbTncrm83n/p0qXR/vOf/zzaJ02aFO3vvfdetFf2a9YHH3wQ7V/60pcqbPl+bqg59er5faq6avr06VW+du3atdU4CRSHXr16RfuMGTOivbS0NK/3nzhxYrT/+c9/zuv+8EklJfG1wCWXXBLtTz/9dLQ3adIk2n/9619H+/333x/tr776arQ3bNgw2p9//vlo79+/f7RXZsWKFXldX9f5ChQAAACA5CylAAAAAEjOUgoAAACA5CylAAAAAEjOUgoAAACA5CylAAAAAEjOUgoAAACA5EoKPUAxePHFF6N90aJF0b5nz55ov/DCC6P95ptvjvZJkyZF+759+6K9Mm+//Xa0f+9738vr/pBaly5dov1Xv/pVtDdv3jzasyyL9l/+8pfRft1110V77969o33s2LHRPn369Gjftm1btL/11lvRXl5eXmG76qqrotdefPHF0b5y5cpop2KdO3eO9rZt2yaahNRKS0urfG1lvx5CXXTjjTdG+6c+9am87r9kyZJonzVrVl73hxN1/fXXR3tlXztWprJ/lwwdOjTad+/endf7V3b//v3753X/TZs2RfvMmTPzun9d50kpAAAAAJKzlAIAAAAgOUspAAAAAJKzlAIAAAAgOUspAAAAAJKzlAIAAAAgOUspAAAAAJIrKfQAdcHu3bvzun7Xrl15XX/LLbdE+89+9rNoLy8vz+v9obY599xzo3306NHRXlpaGu3bt2+P9i1btkT7zJkzo33v3r3R/otf/CKvXkiNGzeO9rvuuivav/3tb1fnOCeVAQMGRHtlf2+ovdq2bRvtZ599dpXvvXnz5ipfC7VV69ato/273/1utFf2tfPOnTuj/YEHHoh2qG73339/tN9zzz3RnmVZtE+dOjXax44dG+35/vd0Zf7t3/6tRu9/xx13RPu2bdtq9P2LnSelAAAAAEjOUgoAAACA5CylAAAAAEjOUgoAAACA5CylAAAAAEjOUgoAAACA5CylAAAAAEiupNADEMK4ceOivWvXrtHeu3fvaO/Xr1+0v/LKK9EOtU3Dhg2jfdKkSdE+YMCAaN+zZ0+0Dxs2LNpXrFgR7Y0bN472k9mZZ55Z6BHqrPPOOy+v699+++1qmoTqVtmveW3bto32P/7xjxW2yn49hNrorLPOivZ58+bV6Ps//vjj0b548eIafX9OPvfee2+033PPPdF+8ODBaF+4cGG0jxkzJtr3798f7ZVp1KhRtPfv3z/aK/v6MpfLRfsDDzwQ7QsWLIh24jwpBQAAAEByllIAAAAAJGcpBQAAAEByllIAAAAAJGcpBQAAAEByllIAAAAAJGcpBQAAAEByJYUegBD27dsX7bfccku0r1y5MtqffvrpaF+8eHG0r1ixItqffPLJaM+yLNrhRF100UXRPmDAgLzu/7WvfS3aly5dmtf9oRgtX7680CMUrebNm0f7l7/85Wi//vrro71///4nPNPfu//++ytsO3fuzOveUAiVnanOnTvndf///u//jvbHHnssr/vDsbRo0aLCNnz48Oi1lf332MKFC6N90KBB0Z6vc845J9pnz54d7V27ds3r/efOnRvtDz/8cF73J86TUgAAAAAkZykFAAAAQHKWUgAAAAAkZykFAAAAQHKWUgAAAAAkZykFAAAAQHKWUgAAAAAkV1LoAajcunXrov2mm26K9hkzZkT7DTfckFc/9dRTo33WrFnRvmXLlmiHT3rkkUeiPZfLRfvSpUvz6sTVq1fx73eUl5cnnITq1LJly4K994UXXhjtlZ35fv36RfunP/3paD/llFOi/dvf/na0x85ECCHs378/2svKyqL9wIED0V5SEv9y73e/+120Q20zaNCgaJ8wYUJe93/11Vej/cYbb4z2Xbt25fX+cCyxfxe1bt06r3vfcccd0X7aaadF+3e+851o/+pXvxrtX/jCF6K9adOm0Z5lWV79ueeei/Z9+/ZFO/nxpBQAAAAAyVlKAQAAAJCcpRQAAAAAyVlKAQAAAJCcpRQAAAAAyVlKAQAAAJCcpRQAAAAAyZUUegDyN3/+/Ghfu3ZttD/yyCPR3rdv32gfP358tLdv3z7aH3zwwWjfvHlztFM3DRw4sMLWpUuX6LVZlkX7Sy+9VJWROE7l5eUVtsr+3rz55pvVPA2H7d+/P9or+3vzk5/8JNrvueeeE57peHXu3Dnac7lctB86dCjaP/zww2h/5513ov2ZZ56J9hUrVkT70qVLo33r1q3RvmnTpmhv3LhxtK9evTraIbWzzjor2ufNm1ej779+/fpor+xMQk04ePBghW3btm3Ra9u0aRPt7777brRX9jVCvt57771o3717d7Sffvrp0b59+/Zo//nPfx7t1CxPSgEAAACQnKUUAAAAAMlZSgEAAACQnKUUAAAAAMlZSgEAAACQnKUUAAAAAMlZSgEAAACQXEmhB6DmrVq1KtqvvfbaaL/66qujfcaMGdF+6623RnvHjh2j/Yorroh26qbGjRtX2E455ZTotX/961+j/Wc/+1mVZjpZNGzYMNrHjRtX5XsvWrQo2u++++4q35u44cOHR/uf//znaO/Zs2d1jnNCNm7cGO0vvvhitP/hD3+I9tdff/1ER0rqe9/7XrS3adMm2tevX1+d40CNGzNmTLSXl5fX6PtPmDChRu8PVbFz584K26BBg6LXvvzyy9HesmXLaF+3bl20L1iwINqfffbZaN+xY0e0z5kzJ9pPP/30vK6nsDwpBQAAAEByllIAAAAAJGcpBQAAAEByllIAAAAAJGcpBQAAAEByllIAAAAAJGcpBQAAAEByJYUegMLbuXNntP/0pz+N9unTp0d7SUn8H7PLLrss2vv06VNhW7JkSfRaTk4HDhyI9i1btiSapHZq2LBhtI8dOzbaR48eHe2bNm2qsE2ePDl67d69e6OdmvPQQw8VegQq0Ldv37yunzdvXjVNAtWjS5cu0d6/f/8aff8FCxZE+5o1a2r0/aG6lZWVRXubNm0STVI1lf33YO/evaO9vLw82tevX3/CM5GOJ6UAAAAASM5SCgAAAIDkLKUAAAAASM5SCgAAAIDkLKUAAAAASM5SCgAAAIDkLKUAAAAASK6k0ANQ8zp37hztQ4YMifZu3bpFe0lJfv8YvfPOO9H+61//Oq/7c/J56aWXCj1CQXXp0iXaR48eHe1Dhw6N9gULFkT74MGDox1Ia/78+YUeAT7mlVdeifZ/+Id/yOv+r7/+erTfdNNNed0fqF6NGzeO9vLy8mjPsiza58yZc8IzkY4npQAAAABIzlIKAAAAgOQspQAAAABIzlIKAAAAgOQspQAAAABIzlIKAAAAgOQspQAAAABIrqTQA1C58847L9pHjBgR7V//+tejvV27dic804n4v//7v2jfsmVLtJeXl1fnOBSJXC5XpRZCCIMGDYr2kSNHVmWkWuPOO++M9h/84AfRXlpaGu2zZ8+O9mHDhkU7AMS0atUq2vP92m/q1KnRvnfv3rzuD1SvhQsXFnoECsiTUgAAAAAkZykFAAAAQHKWUgAAAAAkZykFAAAAQHKWUgAAAAAkZykFAAAAQHKWUgAAAAAkV1LoAU4G7dq1i/brrrsu2keMGBHtZ5111omOVK1WrFgR7Q8++GC0v/TSS9U5DnVElmVVaiFUfuamTJkS7c8880y0v//++9F+6aWXRvsNN9wQ7RdeeGG0f/rTn472jRs3RvvChQujferUqdEO1C65XC7azz333Gh//fXXq3McCDNmzIj2evVq9vfFX3vttRq9P1C9rrzyykKPQAF5UgoAAACA5CylAAAAAEjOUgoAAACA5CylAAAAAEjOUgoAAACA5CylAAAAAEiupNADFIO2bdtG+wUXXBDtTzzxRLSff/75JzxTdSorK4v2iRMnRvuCBQuivby8/IRngnzUr18/2ocPHx7tgwcPjvbdu3dHe8eOHaM9X5V9q+vFixdH+7333lud4wAFlmVZtNer5/cgqV5dunSJ9n79+kV7ZV8bHjx4MNqffPLJaN+6dWu0A7VLhw4dCj0CBeSrFAAAAACSs5QCAAAAIDlLKQAAAACSs5QCAAAAIDlLKQAAAACSs5QCAAAAIDlLKQAAAACSKyn0AKm0bNmywjZt2rTotV26dIn2Dh06VGWkavPaa69F++TJk6N94cKF0b5///4TngnytWzZsgrb8uXLo9d269Ytr/du165dtLdt2zav+7///vvRPmfOnGgfOXJkXu8PnFz+8R//MdqfffbZNINQZ7Ro0SLaK/v3aGU2b94c7aNGjcrr/kDt8pvf/Cba69WLP0tTXl5eneOQmCelAAAAAEjOUgoAAACA5CylAAAAAEjOUgoAAACA5CylAAAAAEjOUgoAAACA5CylAAAAAEiupNADHK8ePXpE++jRo6O9e/fuFbYzzjijSjNVlw8//DDap0yZEu3jx4+P9n379p3wTFBomzZtqrB9/etfj1576623RvvYsWOrNNPxeuyxx6L9qaeeivY//elP1TkOUMflcrlCjwAAVbZq1apoX7t2bbR36NAh2j/72c9G+7Zt26KdmuVJKQAAAACSs5QCAAAAIDlLKQAAAACSs5QCAAAAIDlLKQAAAACSs5QCAAAAIDlLKQAAAACSKyn0AMfrmmuuyavn45133on2l19+OdoPHToU7ZMnT472nTt3RjucbLZs2RLt48aNy6sD1Ca//OUvo/0b3/hGokngb1avXh3tr732WrT36tWrOscB6rjx48dH+/Tp06P9wQcfjPbbb7892ivbB5AfT0oBAAAAkJylFAAAAADJWUoBAAAAkJylFAAAAADJWUoBAAAAkJylFAAAAADJWUoBAAAAkFwuy7LsuF6Yy9X0LMAnHOfxPCZnFtJzZqG4OLNQXJzZk1Pz5s2j/fnnn4/2fv36RfsLL7wQ7d/5zneifd++fdF+MjueM+tJKQAAAACSs5QCAAAAIDlLKQAAAACSs5QCAAAAIDlLKQAAAACSs5QCAAAAIDlLKQAAAACSy2VZlh3XC3O5mp4F+ITjPJ7H5MxCes4sFBdnFoqLM8uxNG/ePNoffPDBaP/+978f7Z07d472d955J9pPZsdzZj0pBQAAAEByllIAAAAAJGcpBQAAAEByllIAAAAAJGcpBQAAAEByllIAAAAAJGcpBQAAAEByuSzLsuN6YS5X07MAn3Ccx/OYnFlIz5mF4uLMQnFxZqG4HM+Z9aQUAAAAAMlZSgEAAACQnKUUAAAAAMlZSgEAAACQnKUUAAAAAMlZSgEAAACQnKUUAAAAAMnlsizLCj0EAAAAACcXT0oBAAAAkJylFAAAAADJWUoBAAAAkJylFAAAAADJWUoBAAAAkJylFAAAAADJWUoBAAAAkJylFAAAAADJWUoBAAAAkNz/AyL1Oh3P4MtGAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data vectorization, also known as feature vectorization, is the process of converting raw data into a numerical representation in the form of vectors or arrays. Data vectorization is a crucial step in preparing data for machine learning tasks. It converts raw data into a numerical format that algorithms can understand, enabling them to learn patterns, make predictions, and perform various data analysis tasks effectively."
      ],
      "metadata": {
        "id": "5AiwulEWxx69"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data representation/vectorization\n",
        "train_images_vectorized = train_images.reshape(train_images.shape[0], -1)\n",
        "test_images_vectorized = test_images.reshape(test_images.shape[0], -1)"
      ],
      "metadata": {
        "id": "ogCV5em7xsLQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data normalization, also known as data scaling or feature scaling, is a preprocessing technique used to bring data into a standardized range. It involves transforming the values of different features or variables in a dataset to a common scale, typically between 0 and 1 or with a mean of 0 and a standard deviation of 1. The goal of data normalization is to ensure that the features have similar scales and distributions, which can improve the performance and stability of machine learning algorithms."
      ],
      "metadata": {
        "id": "yA0X4SAYyW69"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data normalization, if needed\n",
        "train_images_normalized = train_images_vectorized / 255.0\n",
        "test_images_normalized = test_images_vectorized / 255.0\n",
        "\n",
        "def display_images(images, labels, num_images=5):\n",
        "    fig, axes = plt.subplots(1, num_images, figsize=(12, 3))\n",
        "    for i in range(num_images):\n",
        "        axes[i].imshow(images[i].reshape(28, 28), cmap='gray')\n",
        "        axes[i].set_title(f\"Label: {labels[i][0]}\")\n",
        "        axes[i].axis('off')\n",
        "    plt.show()\n",
        "\n",
        "display_images(train_images_normalized, train_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "-1D8GGthygiL",
        "outputId": "19322421-753f-4191-8128-bdcda4193402"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x300 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#codes for data spliiting in different ratios:\n",
        "from sklearn.model_selection import train_test_split\n",
        "def split_data(train_images, train_labels, test_images, test_labels, test_size):\n",
        "    # Concatenate train and test sets for splitting\n",
        "    images = np.concatenate((train_images, test_images))\n",
        "    labels = np.concatenate((train_labels, test_labels))\n",
        "\n",
        "    # Split the data into training and testing sets\n",
        "    train_images, test_images, train_labels, test_labels = train_test_split(\n",
        "        images, labels, test_size=test_size, random_state=42, stratify=labels)\n",
        "\n",
        "    return train_images, train_labels, test_images, test_labels\n",
        "\n",
        "# Load the data\n",
        "train_images, train_labels, test_images, test_labels = load_data()\n",
        "\n",
        "# Ratios for splitting data\n",
        "ratios = [(0.8, 0.2), (0.5, 0.5), (0.2, 0.8), (0.01, 0.99)]\n",
        "\n",
        "for ratio in ratios:\n",
        "    print(f\"\\nSplitting data with ratio {int(ratio[0]*100)}-{int(ratio[1]*100)}\")\n",
        "    train_images_split, train_labels_split, test_images_split, test_labels_split = split_data(\n",
        "        train_images, train_labels, test_images, test_labels, test_size=ratio[1])\n",
        "    print(f\"Number of training samples: {len(train_images_split)}\")\n",
        "    print(f\"Number of testing samples: {len(test_images_split)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "SbbkM2DTyo3O",
        "outputId": "e912274d-0440-48d5-927e-be490e020157"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Splitting data with ratio 80-20\n",
            "Number of training samples: 56000\n",
            "Number of testing samples: 14000\n",
            "\n",
            "Splitting data with ratio 50-50\n",
            "Number of training samples: 35000\n",
            "Number of testing samples: 35000\n",
            "\n",
            "Splitting data with ratio 20-80\n",
            "Number of training samples: 14000\n",
            "Number of testing samples: 56000\n",
            "\n",
            "Splitting data with ratio 1-99\n",
            "Number of training samples: 700\n",
            "Number of testing samples: 69300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#codes for model selection and  training:\n",
        "#In this assignment,four models were used which are logistic regression,decision tree,random forest and support vector machine.\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def train_model(X_train, y_train, X_test, model):\n",
        "    # Function to train a model and return its accuracy\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    return accuracy\n",
        "\n",
        "# Load the data\n",
        "train_images, train_labels, _, _ = load_data()\n",
        "\n",
        "# Data splitting and model training for different ratios\n",
        "ratios = [(0.8, 0.2), (0.5, 0.5), (0.2, 0.8), (0.01, 0.99)]\n",
        "\n",
        "for train_ratio, test_ratio in ratios:\n",
        "    print(f\"Training ratio: {train_ratio}, Testing ratio: {test_ratio}\")\n",
        "    X_train, X_test, y_train, y_test = train_test_split(train_images, train_labels, test_size=test_ratio, random_state=42)\n",
        "\n",
        "    models = {\n",
        "        \"Logistic Regression\": LogisticRegression(),\n",
        "        \"Decision Tree\": DecisionTreeClassifier(),\n",
        "        \"Random Forest\": RandomForestClassifier(),\n",
        "        \"Support Vector Machine\": SVC()\n",
        "    }"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "qaS8H39_yv-V",
        "outputId": "049962fa-b917-4835-cda3-1ccbce80c169"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training ratio: 0.8, Testing ratio: 0.2\n",
            "Training ratio: 0.5, Testing ratio: 0.5\n",
            "Training ratio: 0.2, Testing ratio: 0.8\n",
            "Training ratio: 0.01, Testing ratio: 0.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#codes for model evaluation:\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "\n",
        "def evaluate_model(y_true, y_pred):\n",
        "    # Calculate evaluation metrics\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, average='weighted')\n",
        "    recall = recall_score(y_true, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    return accuracy, precision, recall, f1, cm\n",
        "\n",
        "# Load the data\n",
        "train_images, train_labels, _, _ = load_data()\n",
        "\n",
        "# Data splitting and model training for different ratios and algorithms\n",
        "ratios = [(0.8, 0.2), (0.5, 0.5), (0.2, 0.8), (0.01, 0.99)]\n",
        "\n",
        "for train_ratio, test_ratio in ratios:\n",
        "    print(f\"Training ratio: {train_ratio}, Testing ratio: {test_ratio}\")\n",
        "    X_train, X_test, y_train, y_test = train_test_split(train_images, train_labels, test_size=test_ratio, random_state=42)\n",
        "\n",
        "    models = {\n",
        "        \"Logistic Regression\": LogisticRegression(),\n",
        "        \"Decision Tree\": DecisionTreeClassifier(),\n",
        "        \"Random Forest\": RandomForestClassifier(),\n",
        "        \"Support Vector Machine\": SVC()\n",
        "    }\n",
        "\n",
        "    for model_name, model in models.items():\n",
        "        # Train the model\n",
        "        model.fit(X_train, y_train.ravel())\n",
        "\n",
        "        # Predictions\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # Evaluate the model\n",
        "        accuracy, precision, recall, f1, cm = evaluate_model(y_test, y_pred)\n",
        "        print(f\"Model: {model_name}\")\n",
        "        print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}\")\n",
        "        print(\"Confusion Matrix:\")\n",
        "        print(cm)\n",
        "        print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "H8542LuBy3qe",
        "outputId": "e5474899-da94-4481-bf27-ae614f669b2f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training ratio: 0.8, Testing ratio: 0.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: Logistic Regression\n",
            "Accuracy: 0.9223, Precision: 0.9221, Recall: 0.9223, F1-score: 0.9221\n",
            "Confusion Matrix:\n",
            "[[1139    0    6    3    4    4    5    4    8    2]\n",
            " [   0 1283    8    6    2    3    1    2   13    4]\n",
            " [   1   18 1054   14   13    5   18   17   29    5]\n",
            " [   4    8   36 1090    1   32    2    9   22   15]\n",
            " [   4    2    5    2 1108    3    9    4    7   32]\n",
            " [  15    5   14   39    9  961   11    4   38    8]\n",
            " [  11    0   15    1    9   14 1120    2    5    0]\n",
            " [   5    7   15    9   10    2    0 1209    6   36]\n",
            " [  10   13   14   31    9   32   10    4 1028    9]\n",
            " [   5    4    5   14   28   10    0   39   14 1075]]\n",
            "\n",
            "Model: Decision Tree\n",
            "Accuracy: 0.8643, Precision: 0.8640, Recall: 0.8643, F1-score: 0.8641\n",
            "Confusion Matrix:\n",
            "[[1066    1   20    9    5   18   17   10   14   15]\n",
            " [   0 1270    4   11    3    8    9    4   11    2]\n",
            " [  14   16  998   25   22   11   10   20   43   15]\n",
            " [  13   14   31 1016    7   59   10   13   28   28]\n",
            " [   2    6   16    4 1019    8   12   16   25   68]\n",
            " [  19   16   14   62    9  895   28    7   34   20]\n",
            " [  18   10   19    5   25   22 1045    3   25    5]\n",
            " [   3   16   21   21   12    7    6 1171   12   30]\n",
            " [  17   17   39   54   30   38   20   13  905   27]\n",
            " [   6   14   12   15   61   24    2   38   35  987]]\n",
            "\n",
            "Model: Random Forest\n",
            "Accuracy: 0.9688, Precision: 0.9688, Recall: 0.9688, F1-score: 0.9687\n",
            "Confusion Matrix:\n",
            "[[1155    0    1    1    3    3    3    0    7    2]\n",
            " [   0 1303    8    5    2    0    1    1    0    2]\n",
            " [   2    6 1140    5    2    0    3    8    6    2]\n",
            " [   4    0   13 1162    0   13    0    9    9    9]\n",
            " [   1    0    2    1 1139    0    6    4    1   22]\n",
            " [   6    2    2    9    3 1063    4    2   10    3]\n",
            " [   6    0    1    0    2    7 1159    0    2    0]\n",
            " [   0    9   14    2    6    0    0 1255    2   11]\n",
            " [   1    3    8    9   10    6    4    2 1113    4]\n",
            " [   6    2    4   11   15    3    2   12    3 1136]]\n",
            "\n",
            "Model: Support Vector Machine\n",
            "Accuracy: 0.9776, Precision: 0.9776, Recall: 0.9776, F1-score: 0.9776\n",
            "Confusion Matrix:\n",
            "[[1163    0    3    0    2    3    1    0    2    1]\n",
            " [   0 1310    5    2    1    0    0    0    1    3]\n",
            " [   1    5 1149    2    5    1    0    6    4    1]\n",
            " [   1    1   15 1169    0   11    0    4   13    5]\n",
            " [   2    0    2    0 1157    0    1    2    0   12]\n",
            " [   3    1    3   12    4 1069    5    1    5    1]\n",
            " [   1    1    1    0    1    3 1166    0    4    0]\n",
            " [   1    7   12    3    6    0    0 1263    3    4]\n",
            " [   1    2    4    6    6    6    2    2 1128    3]\n",
            " [   4    2    1    1   14    3    0    8    4 1157]]\n",
            "\n",
            "Training ratio: 0.5, Testing ratio: 0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: Logistic Regression\n",
            "Accuracy: 0.9137, Precision: 0.9135, Recall: 0.9137, F1-score: 0.9135\n",
            "Confusion Matrix:\n",
            "[[2834    1   13    5   13   25   25    9   26    5]\n",
            " [   0 3236   21   15    5   11    2    4   27    8]\n",
            " [  19   28 2602   49   30   12   54   44   59   23]\n",
            " [  11   11   84 2733    2  100   11   26   64   35]\n",
            " [   7   13   20    3 2704    7   36   11   19  110]\n",
            " [  37   13   32  113   23 2366   42    8   98   35]\n",
            " [  20    2   28    5   27   43 2879    7   10    1]\n",
            " [   8   13   43   21   34    4    0 2901    8  126]\n",
            " [  20   65   47   87   18   96   34    9 2446   34]\n",
            " [  16   14   10   36   78   17    0   80   24 2710]]\n",
            "\n",
            "Model: Decision Tree\n",
            "Accuracy: 0.8493, Precision: 0.8490, Recall: 0.8493, F1-score: 0.8491\n",
            "Confusion Matrix:\n",
            "[[2675    1   39   39   17   47   57   12   36   33]\n",
            " [   3 3149   28   25   16   18   12   25   45    8]\n",
            " [  39   29 2408   74   46   42   60   70  114   38]\n",
            " [  23   20   96 2493   17  170   34   45  112   67]\n",
            " [  24   28   43   18 2490   26   41   57   55  148]\n",
            " [  48   36   31  155   33 2196   80   26   80   82]\n",
            " [  41   27   43   24   68   82 2664    3   46   24]\n",
            " [   5   36   73   46   38   26    5 2815   32   82]\n",
            " [  26   59  103   76   80   99   63   44 2190  116]\n",
            " [  22   14   33   62  172   75    8  113   88 2398]]\n",
            "\n",
            "Model: Random Forest\n",
            "Accuracy: 0.9624, Precision: 0.9624, Recall: 0.9624, F1-score: 0.9623\n",
            "Confusion Matrix:\n",
            "[[2900    0    3    2    3    6   17    1   22    2]\n",
            " [   0 3272   21   12    6    4    5    2    4    3]\n",
            " [  11    7 2824   14   13    1   11   20   15    4]\n",
            " [   6    2   53 2894    3   40    6   27   31   15]\n",
            " [   5    6    5    0 2833    0   15   11    4   51]\n",
            " [  17    4    5   42    6 2628   24    2   24   15]\n",
            " [  11    2    2    0    6   20 2976    0    5    0]\n",
            " [   4   16   38    5   15    0    0 3033    8   39]\n",
            " [   4   17   22   36   18   26   21    2 2679   31]\n",
            " [  10    8    9   31   38    8    2   26   21 2832]]\n",
            "\n",
            "Model: Support Vector Machine\n",
            "Accuracy: 0.9727, Precision: 0.9727, Recall: 0.9727, F1-score: 0.9727\n",
            "Confusion Matrix:\n",
            "[[2917    1    6    1    4    5    8    2   10    2]\n",
            " [   0 3284   20    8    5    0    1    2    4    5]\n",
            " [   3    8 2837   13   12    6   10   20    8    3]\n",
            " [   3    3   36 2940    2   33    1   17   31   11]\n",
            " [   2    7    5    0 2861    0   12    8    2   33]\n",
            " [  10    2    4   35    7 2675   17    0   12    5]\n",
            " [   5    1    5    0    7   13 2986    0    5    0]\n",
            " [   2   15   22    6   23    1    0 3062    3   24]\n",
            " [   2   14   10   19   16   24    8    6 2745   12]\n",
            " [   9    7    3   15   37    6    1   25    8 2874]]\n",
            "\n",
            "Training ratio: 0.2, Testing ratio: 0.8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: Logistic Regression\n",
            "Accuracy: 0.8857, Precision: 0.8851, Recall: 0.8857, F1-score: 0.8853\n",
            "Confusion Matrix:\n",
            "[[4540    1   36   19   12   37   44   12   39   11]\n",
            " [   2 5180   30   35    8   24    7   15   49    5]\n",
            " [  43   54 4130  134   40   28   86   87  106   34]\n",
            " [  25   33  164 4261    9  204   17   35  155   63]\n",
            " [  14   17   31   11 4235   22   72   24   47  230]\n",
            " [  99   23   47  227   47 3471  125   21  227   68]\n",
            " [  55    7   76    8   61   75 4389    3   30    7]\n",
            " [  29   20   67   60   64    9    3 4482   14  259]\n",
            " [  40  101  146  205   37  188   51   33 3754   92]\n",
            " [  24   21   30   73  199   51    5  227   63 4070]]\n",
            "\n",
            "Model: Decision Tree\n",
            "Accuracy: 0.8160, Precision: 0.8151, Recall: 0.8160, F1-score: 0.8154\n",
            "Confusion Matrix:\n",
            "[[4202   15  103   66   32   98   62   53   74   46]\n",
            " [   6 4981   62   66   44   30   32   34   80   20]\n",
            " [ 147   99 3576  194   86  102  166  143  152   77]\n",
            " [  50   85  191 3815   63  240   53   94  226  149]\n",
            " [  31   64   78   51 3793   52   96   82  146  310]\n",
            " [ 106   60   83  230   56 3248  165   71  168  168]\n",
            " [  84   34  108   49   81  174 4041   11   81   48]\n",
            " [  26   68  149   75   55   36   14 4396   40  148]\n",
            " [  90  145  202  236  131  170   96   56 3342  179]\n",
            " [  39   47   58   97  263  108   21  247  108 3775]]\n",
            "\n",
            "Model: Random Forest\n",
            "Accuracy: 0.9516, Precision: 0.9515, Recall: 0.9516, F1-score: 0.9515\n",
            "Confusion Matrix:\n",
            "[[4662    1    7    4    3   10   28    1   33    2]\n",
            " [   0 5261   28   17   10   11    6   10    8    4]\n",
            " [  33   14 4513   22   35    6   33   43   37    6]\n",
            " [  12   12   98 4578    4   99   11   45   63   44]\n",
            " [  12    8    8    0 4494    2   31   12   14  122]\n",
            " [  33   13   10   86   11 4049   59    5   42   47]\n",
            " [  30    9    7    0   13   21 4615    0   16    0]\n",
            " [  12   26   58    9   32    1    0 4772   14   83]\n",
            " [  12   40   42   58   29   44   27    8 4315   72]\n",
            " [  32   13   12   71   88   18    5   57   50 4417]]\n",
            "\n",
            "Model: Support Vector Machine\n",
            "Accuracy: 0.9633, Precision: 0.9633, Recall: 0.9633, F1-score: 0.9632\n",
            "Confusion Matrix:\n",
            "[[4685    2    8    3    7    7   17    0   16    6]\n",
            " [   1 5277   20   16   10    4    3    8    9    7]\n",
            " [  19   19 4555   24   33    6   23   28   28    7]\n",
            " [   4   13   75 4682    4   79    4   30   53   22]\n",
            " [   5    9   11    0 4560    0   22    7    8   81]\n",
            " [  17   12   12   66   15 4144   45    3   22   19]\n",
            " [  18    6   13    0   11   29 4626    0    8    0]\n",
            " [  12   23   31    9   40    4    1 4826    4   57]\n",
            " [   6   40   27   52   17   47   27    6 4401   24]\n",
            " [  17   14    5   43   92   15    1   64   30 4482]]\n",
            "\n",
            "Training ratio: 0.01, Testing ratio: 0.99\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: Logistic Regression\n",
            "Accuracy: 0.8302, Precision: 0.8295, Recall: 0.8302, F1-score: 0.8290\n",
            "Confusion Matrix:\n",
            "[[5553    0   63   35    6  138   22    7   29   14]\n",
            " [   2 6494   29   28   11   23   31   17   28   12]\n",
            " [ 108   81 4816  179   52   26  176  116  307   34]\n",
            " [  70   43  226 4813   34  354   79   45  294  107]\n",
            " [  51   28  128   11 4763   39  185   45   40  503]\n",
            " [ 145   85  135  413  126 3692  253   20  356  145]\n",
            " [ 173   25  178   15  105   53 5225   23   56    3]\n",
            " [  74   78  131  103  169  103    6 4975   53  513]\n",
            " [  42  264  178  272  148  290   87   34 4322  146]\n",
            " [  64   46  142  141  361   56   26  226  170 4659]]\n",
            "\n",
            "Model: Decision Tree\n",
            "Accuracy: 0.6157, Precision: 0.6156, Recall: 0.6157, F1-score: 0.6133\n",
            "Confusion Matrix:\n",
            "[[5004   11  175  156   75  116   89   26  167   48]\n",
            " [  10 5527  411  102   48   95   90  111  274    7]\n",
            " [ 380  371 3265  237  303  214  334  170  568   53]\n",
            " [ 128  283  483 3032  220  534  247  168  741  229]\n",
            " [ 135  132  342  281 3207  120  241  426  196  713]\n",
            " [ 391  168  387  384  242 2408  602   70  456  262]\n",
            " [ 229  119  500   90  469  248 3974   88  120   19]\n",
            " [ 179  144  374  164  121  431  430 3480  216  666]\n",
            " [ 108  380  660  482  187  367  226  135 3107  131]\n",
            " [ 148   85  458  450  166  159  107  466  286 3566]]\n",
            "\n",
            "Model: Random Forest\n",
            "Accuracy: 0.8646, Precision: 0.8687, Recall: 0.8646, F1-score: 0.8640\n",
            "Confusion Matrix:\n",
            "[[5601    1   18   40    8   34  100    2   60    3]\n",
            " [   0 6490   35   17    6   13   14   14   82    4]\n",
            " [  76  215 4979  161   46    8  177   86  129   18]\n",
            " [  35  118  176 5160   12  135   45   49  273   62]\n",
            " [   9   51   37   13 4930    5  172   12   55  509]\n",
            " [  73  103   27  915   61 3721  154   10  139  167]\n",
            " [  78   96   65    7  100   40 5460    1    9    0]\n",
            " [  67  144  142   60  123   16    2 5328   50  273]\n",
            " [  28  154   91  567   36   88   80   12 4581  146]\n",
            " [  33   63   50  125  210   27   17  131  125 5110]]\n",
            "\n",
            "Model: Support Vector Machine\n",
            "Accuracy: 0.8936, Precision: 0.8952, Recall: 0.8936, F1-score: 0.8936\n",
            "Confusion Matrix:\n",
            "[[5579    1   41   35    4   71   68    2   47   19]\n",
            " [   0 6494   34   25    9   31   12    8   56    6]\n",
            " [  43   76 5219  111   66   19  100   51  193   17]\n",
            " [  23   51  175 5334   10  141   30   41  222   38]\n",
            " [   4   37   83    2 5054    4   82    6   31  490]\n",
            " [  39   45   44  494   34 4415  123    5   72   99]\n",
            " [  61   39  101    2   54   55 5530    0   14    0]\n",
            " [  18  112  112   42  184   47    1 5326   56  307]\n",
            " [  17  105  104  374   38  132   43   14 4845  111]\n",
            " [  21   46   44  109  169   22    6  104   87 5283]]\n",
            "\n"
          ]
        }
      ]
    }
  ]
}